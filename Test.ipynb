{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:25:42.714780Z",
     "iopub.status.busy": "2021-10-05T19:25:42.714094Z",
     "iopub.status.idle": "2021-10-05T19:25:42.720965Z",
     "shell.execute_reply": "2021-10-05T19:25:42.720182Z",
     "shell.execute_reply.started": "2021-10-05T19:25:42.714744Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.utils.data import Sampler\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-05T18:56:22.333081Z",
     "iopub.status.busy": "2021-10-05T18:56:22.332539Z",
     "iopub.status.idle": "2021-10-05T18:56:22.347197Z",
     "shell.execute_reply": "2021-10-05T18:56:22.346489Z",
     "shell.execute_reply.started": "2021-10-05T18:56:22.333043Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    \n",
    "    mean=[0.485,0.456,0.406]\n",
    "    std=[0.229,0.224,0.225]\n",
    "    normalize = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=mean,std=std)])\n",
    "    size_transform = transforms.Resize([84,84])\n",
    "    \n",
    "    eval_transform = transforms.Compose([size_transform,normalize])\n",
    "    return eval_transform\n",
    "     \n",
    "def image_loader(path):\n",
    "    \n",
    "    p = Image.open(path)\n",
    "    p = p.convert('RGB')\n",
    "    final_transform = get_transform()\n",
    "    p = final_transform(p)\n",
    "    return p\n",
    "\n",
    "class CustomDataset_Support(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        dir_p = '../input/snap-retail-data/final_data/query_data/support/'\n",
    "        img_p = dir_p+self.df.loc[idx, 'class'].astype(str) + '_' + self.df.loc[idx, 'image_id']\n",
    "        target = self.df.loc[idx,'class_code']\n",
    "        img= image_loader(img_p)\n",
    "        \n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "# Dataset class for Validation - 10%of data\n",
    "class CustomDataset_Query(object):\n",
    "    def __init__(self, df, is_trained_class=True):\n",
    "        self.df = df\n",
    "        self.is_trained_class = is_trained_class\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_trained_class:\n",
    "            dir_p = '../input/snap-retail-data/final_data/query_data/valid_query/'\n",
    "            img_p = dir_p+self.df.loc[idx, 'class'].astype(str) + '_' +self.df.loc[idx, 'image_id']\n",
    "        else:\n",
    "            dir_p = '../input/snap-retail-data/final_data/query_data/test_query/'\n",
    "            img_p = dir_p+self.df.loc[idx, 'class'].astype(str) + '_' +self.df.loc[idx, 'image_id']\n",
    "        target = self.df.loc[idx,'class_code']\n",
    "        img= image_loader(img_p)\n",
    "        \n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T04:49:49.988516Z",
     "iopub.status.busy": "2021-10-04T04:49:49.988188Z",
     "iopub.status.idle": "2021-10-04T04:49:51.961596Z",
     "shell.execute_reply": "2021-10-04T04:49:51.961007Z",
     "shell.execute_reply.started": "2021-10-04T04:49:49.988485Z"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T18:56:29.835961Z",
     "iopub.status.busy": "2021-10-05T18:56:29.835500Z",
     "iopub.status.idle": "2021-10-05T18:56:29.875248Z",
     "shell.execute_reply": "2021-10-05T18:56:29.874503Z",
     "shell.execute_reply.started": "2021-10-05T18:56:29.835927Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class DropBlock(nn.Module):\n",
    "    def __init__(self, block_size):\n",
    "        super(DropBlock, self).__init__()\n",
    "\n",
    "        self.block_size = block_size\n",
    "\n",
    "\n",
    "    def forward(self, x, gamma):\n",
    "        # shape: (bsize, channels, height, width)\n",
    "\n",
    "        if self.training:\n",
    "            batch_size, channels, height, width = x.shape\n",
    "            \n",
    "            bernoulli = Bernoulli(gamma)\n",
    "            mask = bernoulli.sample((batch_size, channels, height - (self.block_size - 1), width - (self.block_size - 1))).cuda()\n",
    "            block_mask = self._compute_block_mask(mask)\n",
    "            countM = block_mask.size()[0] * block_mask.size()[1] * block_mask.size()[2] * block_mask.size()[3]\n",
    "            count_ones = block_mask.sum()\n",
    "\n",
    "            return block_mask * x * (countM / count_ones)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def _compute_block_mask(self, mask):\n",
    "        left_padding = int((self.block_size-1) / 2)\n",
    "        right_padding = int(self.block_size / 2)\n",
    "        \n",
    "        batch_size, channels, height, width = mask.shape\n",
    "        non_zero_idxs = mask.nonzero()\n",
    "        nr_blocks = non_zero_idxs.shape[0]\n",
    "\n",
    "        offsets = torch.stack(\n",
    "            [\n",
    "                torch.arange(self.block_size).view(-1, 1).expand(self.block_size, self.block_size).reshape(-1), # - left_padding,\n",
    "                torch.arange(self.block_size).repeat(self.block_size), #- left_padding\n",
    "            ]\n",
    "        ).t().cuda()\n",
    "        offsets = torch.cat((torch.zeros(self.block_size**2, 2).cuda().long(), offsets.long()), 1)\n",
    "        \n",
    "        if nr_blocks > 0:\n",
    "            non_zero_idxs = non_zero_idxs.repeat(self.block_size ** 2, 1)\n",
    "            offsets = offsets.repeat(nr_blocks, 1).view(-1, 4)\n",
    "            offsets = offsets.long()\n",
    "\n",
    "            block_idxs = non_zero_idxs + offsets\n",
    "            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n",
    "            padded_mask[block_idxs[:, 0], block_idxs[:, 1], block_idxs[:, 2], block_idxs[:, 3]] = 1.\n",
    "        else:\n",
    "            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n",
    "            \n",
    "        block_mask = 1 - padded_mask#[:height, :width]\n",
    "        return block_mask\n",
    "    \n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, drop_rate=0.0, drop_block=False,\n",
    "                 block_size=1,max_pool=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv3x3(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.maxpool = nn.MaxPool2d(stride)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.drop_rate = drop_rate\n",
    "        self.num_batches_tracked = 0\n",
    "        self.drop_block = drop_block\n",
    "        self.block_size = block_size\n",
    "        self.DropBlock = DropBlock(block_size=self.block_size)\n",
    "        self.max_pool = max_pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.num_batches_tracked += 1\n",
    "\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        if self.max_pool:\n",
    "            out = self.maxpool(out)\n",
    "\n",
    "        if self.drop_rate > 0:\n",
    "            if self.drop_block == True:\n",
    "                feat_size = out.size()[2]\n",
    "                keep_rate = max(1.0 - self.drop_rate / (20*2000) * (self.num_batches_tracked), 1.0 - self.drop_rate)\n",
    "                gamma = (1 - keep_rate) / self.block_size**2 * feat_size**2 / (feat_size - self.block_size + 1)**2\n",
    "                out = self.DropBlock(out, gamma=gamma)\n",
    "            else:\n",
    "                out = F.dropout(out, p=self.drop_rate, training=self.training, inplace=True)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, n_blocks, drop_rate=0.0, dropblock_size=5, max_pool=True):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 3\n",
    "        self.layer1 = self._make_layer(block, n_blocks[0], 64,\n",
    "                                       stride=2, drop_rate=drop_rate)\n",
    "        self.layer2 = self._make_layer(block, n_blocks[1], 160,\n",
    "                                       stride=2, drop_rate=drop_rate)\n",
    "        self.layer3 = self._make_layer(block, n_blocks[2], 320,\n",
    "                                       stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size)\n",
    "        self.layer4 = self._make_layer(block, n_blocks[3], 640,\n",
    "                                       stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size,max_pool=max_pool)\n",
    "\n",
    "        self.drop_rate = drop_rate\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, n_block, planes, stride=1, drop_rate=0.0, drop_block=False, block_size=1,max_pool=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        if n_block == 1:\n",
    "            layer = block(self.inplanes, planes, stride, downsample, drop_rate, drop_block, block_size,max_pool=max_pool)\n",
    "        else:\n",
    "            layer = block(self.inplanes, planes, stride, downsample, drop_rate)\n",
    "        layers.append(layer)\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1, n_block):\n",
    "            if i == n_block - 1:\n",
    "                layer = block(self.inplanes, planes, drop_rate=drop_rate, drop_block=drop_block,\n",
    "                              block_size=block_size)\n",
    "            else:\n",
    "                layer = block(self.inplanes, planes, drop_rate=drop_rate)\n",
    "            layers.append(layer)\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, is_feat=False):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def resnet12(drop_rate=0.0, max_pool=True, **kwargs):\n",
    "        \"\"\"Constructs a ResNet-12 model.\n",
    "        \"\"\"\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], drop_rate=drop_rate, max_pool=max_pool, **kwargs)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T18:56:31.015551Z",
     "iopub.status.busy": "2021-10-05T18:56:31.015076Z",
     "iopub.status.idle": "2021-10-05T18:56:31.037612Z",
     "shell.execute_reply": "2021-10-05T18:56:31.036903Z",
     "shell.execute_reply.started": "2021-10-05T18:56:31.015517Z"
    }
   },
   "outputs": [],
   "source": [
    "class FRN(nn.Module):\n",
    "    \n",
    "    def __init__(self,way=None,shots=None,is_pretraining=False,num_cat=None):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        num_channel = 640\n",
    "        self.feature_extractor = ResNet.resnet12()\n",
    "\n",
    "        self.shots = shots\n",
    "        self.way = way\n",
    "\n",
    "        # number of channels for the feature map, correspond to d in the paper\n",
    "        self.d = num_channel\n",
    "        \n",
    "        # temperature scaling, correspond to gamma in the paper\n",
    "        self.scale = nn.Parameter(torch.FloatTensor([1.0]),requires_grad=True)\n",
    "        \n",
    "        # H*W=5*5=25, resolution of feature map, correspond to r in the paper\n",
    "        self.resolution = 25\n",
    "\n",
    "        # correpond to [alpha, beta] in the paper\n",
    "        # if is during pre-training, we fix them to 0\n",
    "        self.r = nn.Parameter(torch.zeros(2),requires_grad=not is_pretraining)\n",
    "\n",
    "        if is_pretraining:\n",
    "            # number of categories during pre-training\n",
    "            self.num_cat = num_cat\n",
    "            # category matrix, correspond to matrix M of section 3.6 in the paper\n",
    "            self.cat_mat = nn.Parameter(torch.randn(self.num_cat,self.resolution,self.d),requires_grad=True)   \n",
    "    \n",
    "\n",
    "    def get_feature_map(self,inp):\n",
    "\n",
    "        batch_size = inp.size(0)\n",
    "        feature_map = self.feature_extractor(inp)\n",
    "        \n",
    "        feature_map = feature_map/np.sqrt(640)\n",
    "        \n",
    "#         print('Feature Extracted Shape: ', feature_map.shape)\n",
    "        return feature_map.view(batch_size,self.d,-1).permute(0,2,1).contiguous() # N,HW,C\n",
    "    \n",
    "\n",
    "    def get_recon_dist(self,query,support,alpha,beta,Woodbury=True):\n",
    "    # query: way*query_shot*resolution, d\n",
    "    # support: way, shot*resolution , d\n",
    "    # Woodbury: whether to use the Woodbury Identity as the implementation or not\n",
    "\n",
    "        # correspond to kr/d in the paper\n",
    "        reg = support.size(1)/support.size(2)\n",
    "        \n",
    "        # correspond to lambda in the paper\n",
    "        lam = reg*alpha.exp()+1e-6\n",
    "\n",
    "        # correspond to gamma in the paper\n",
    "        rho = beta.exp()\n",
    "\n",
    "        st = support.permute(0,2,1) # way, d, shot*resolution\n",
    "\n",
    "        if Woodbury:\n",
    "            # correspond to Equation 10 in the paper\n",
    "            \n",
    "            sts = st.matmul(support) # way, d, d\n",
    "            m_inv = (sts+torch.eye(sts.size(-1)).to(sts.device).unsqueeze(0).mul(lam)).inverse() # way, d, d\n",
    "            hat = m_inv.matmul(sts) # way, d, d\n",
    "        \n",
    "        else:\n",
    "            # correspond to Equation 8 in the paper\n",
    "            \n",
    "            sst = support.matmul(st) # way, shot*resolution, shot*resolution\n",
    "            m_inv = (sst+torch.eye(sst.size(-1)).to(sst.device).unsqueeze(0).mul(lam)).inverse() # way, shot*resolution, shot*resolutionsf \n",
    "            hat = st.matmul(m_inv).matmul(support) # way, d, d\n",
    "\n",
    "        Q_bar = query.matmul(hat).mul(rho) # way, way*query_shot*resolution, d\n",
    "\n",
    "        dist = (Q_bar-query.unsqueeze(0)).pow(2).sum(2).permute(1,0) # way*query_shot*resolution, way\n",
    "        \n",
    "        return dist\n",
    "\n",
    "    \n",
    "    def get_neg_l2_dist(self,support_inp, query_inp, batch):\n",
    "        \n",
    "        resolution = self.resolution\n",
    "        d = self.d\n",
    "        alpha = self.r[0]\n",
    "        beta = self.r[1]\n",
    "        \n",
    "        support_feature_map = self.get_feature_map(support_inp)\n",
    "#         print('Input Shape: ', support_inp.shape)\n",
    "#         print('Suport Feature Map: ', support_feature_map.shape)\n",
    "        query_feature_map = self.get_feature_map(query_inp)\n",
    "#         print('Query Feature Map: ', query_feature_map.shape)\n",
    "        support = support_feature_map.view(194, resolution , d)\n",
    "        query = query_feature_map.view(batch*resolution, d)\n",
    "        recon_dist = self.get_recon_dist(query=query, support=support, alpha=alpha,beta=beta) # way*query_shot*resolution, way\n",
    "#         print('Reconstructed Q: ', recon_dist.shape)\n",
    "        neg_l2_dist = recon_dist.neg().view(batch,resolution,194).mean(1) # way*query_shot, way\n",
    "        return neg_l2_dist, support\n",
    "\n",
    "\n",
    "    def meta_test(self,support_inp, query_inp, batch):\n",
    "        neg_l2_dist = self.get_neg_l2_dist(support_inp=support_inp, query_inp = query_inp, batch=batch)\n",
    "        max_values,max_index = torch.max(neg_l2_dist[0],1)\n",
    "        return max_values, max_index, neg_l2_dist\n",
    "\n",
    "\n",
    "    def forward(self,inp):\n",
    "\n",
    "        neg_l2_dist, support = self.get_neg_l2_dist(inp=inp,\n",
    "                                                    way=self.way,\n",
    "                                                    shot=self.shots[0],\n",
    "                                                    query_shot=self.shots[1])\n",
    "            \n",
    "        logits = neg_l2_dist*self.scale\n",
    "        log_prediction = F.log_softmax(logits,dim=1)\n",
    "\n",
    "        return log_prediction, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T18:56:34.679707Z",
     "iopub.status.busy": "2021-10-05T18:56:34.679443Z",
     "iopub.status.idle": "2021-10-05T18:56:34.686998Z",
     "shell.execute_reply": "2021-10-05T18:56:34.686114Z",
     "shell.execute_reply.started": "2021-10-05T18:56:34.679679Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_device_map(gpu):\n",
    "    cuda = lambda x: 'cuda:%d'%x\n",
    "    temp = {}\n",
    "    for i in range(4):\n",
    "        temp[cuda(i)]=cuda(gpu)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T18:56:58.862681Z",
     "iopub.status.busy": "2021-10-05T18:56:58.862225Z",
     "iopub.status.idle": "2021-10-05T19:21:51.274312Z",
     "shell.execute_reply": "2021-10-05T19:21:51.273577Z",
     "shell.execute_reply.started": "2021-10-05T18:56:58.862646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.34it/s]\n",
      "3140it [24:48,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "support_data = pd.read_csv('../input/snap-retail-data/final_data/support.csv')\n",
    "support_data.drop_duplicates('class', inplace=True)\n",
    "valid_query_data = pd.read_csv('../input/snap-retail-data/final_data/valid_query.csv')\n",
    "test_query_data = pd.read_csv('../input/snap-retail-data/final_data/test_query.csv')\n",
    "test_query_data.drop(test_query_data[test_query_data['image_id'] == '.DS_Store'].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "data = pd.concat([support_data, valid_query_data, test_query_data], ignore_index=True)\n",
    "class_codes = {}\n",
    "for idx,cl in enumerate(data['class'].unique()):\n",
    "    class_codes[str(cl)] = idx\n",
    "    \n",
    "for idx in data['class'].index:\n",
    "    data.loc[idx,'class_code'] = class_codes[str(data.loc[idx,'class'])]\n",
    "    \n",
    "data['class_code'] = data['class_code'].astype(int)\n",
    "\n",
    "BS = 194\n",
    "BS_test = 1\n",
    "support_df = data[data['type'] == 'support'].reset_index()\n",
    "valid_query_df = data[data['type'] == 'valid'].reset_index()\n",
    "test_query_df = data[data['type'] == 'test'].reset_index()\n",
    "final_test_data_20 = pd.DataFrame()\n",
    "for cl_,val in zip(test_query_df['class'].value_counts().index,test_query_df['class'].value_counts().values):\n",
    "    if val >= 20:\n",
    "        df = test_query_df[test_query_df['class'] == cl_][:20]\n",
    "        final_test_data_20 = pd.concat([final_test_data_20, df], ignore_index = True)\n",
    "dataset = CustomDataset_Support(support_df)\n",
    "support_data_loader = torch.utils.data.DataLoader(dataset, batch_size=194)\n",
    "valid_query_dataset = CustomDataset_Query(valid_query_df)\n",
    "valid_query_data_loader = torch.utils.data.DataLoader(valid_query_dataset, batch_size=BS)\n",
    "test_query_dataset = CustomDataset_Query(final_test_data_20, is_trained_class = False)\n",
    "test_query_data_loader = torch.utils.data.DataLoader(test_query_dataset, batch_size=BS_test)\n",
    "\n",
    "model_path = '../input/2-shot-learning/best_model_ResNet-12-sgd-lr_1e-01-gamma_1e-01-epoch_100-stage_2-decay_5e-04-way_10.pth'\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "model = FRN()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(model_path,map_location=get_device_map(gpu)),strict=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    c = 0\n",
    "#     for data_load, batch, df in zip([valid_query_data_loader, test_query_data_loader],[BS,BS_test],[valid_query_df, test_query_df]):\n",
    "    for data_load, batch, df in zip([test_query_data_loader],[BS_test],[test_query_df]):\n",
    "        for i, (inp,_) in tqdm(enumerate(support_data_loader)):\n",
    "            inp = inp.cuda()\n",
    "            support_inp = inp\n",
    "        true_label = []\n",
    "        pred_label = []\n",
    "        max_value = []\n",
    "        for i, (inp,target) in tqdm(enumerate(data_load)):\n",
    "            inp = inp.cuda()\n",
    "            target = target.cuda()\n",
    "            max_values, max_index, neg_l2_dist = model.meta_test(support_inp, inp, batch)\n",
    "            true_label.extend(list(target.cpu().numpy()))\n",
    "            pred_label.extend(list(max_index.cpu().numpy()))\n",
    "            max_value.extend(list(max_values.cpu().numpy()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:21:58.850646Z",
     "iopub.status.busy": "2021-10-05T19:21:58.850056Z",
     "iopub.status.idle": "2021-10-05T19:21:58.867709Z",
     "shell.execute_reply": "2021-10-05T19:21:58.866698Z",
     "shell.execute_reply.started": "2021-10-05T19:21:58.850608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Pred Score'] = max_value\n",
    "df['True_Label'] = np.array(true_label) \n",
    "df['Predicted_Label'] = np.array(pred_label)\n",
    "final_test_data_20 = pd.concat([final_test_data_20, df], axis=1)\n",
    "final_test_data_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T18:05:58.298112Z",
     "iopub.status.busy": "2021-10-05T18:05:58.297852Z",
     "iopub.status.idle": "2021-10-05T18:05:58.308292Z",
     "shell.execute_reply": "2021-10-05T18:05:58.307374Z",
     "shell.execute_reply.started": "2021-10-05T18:05:58.298084Z"
    }
   },
   "source": [
    "## Images Less than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:22:22.725787Z",
     "iopub.status.busy": "2021-10-05T19:22:22.725374Z",
     "iopub.status.idle": "2021-10-05T19:25:04.997903Z",
     "shell.execute_reply": "2021-10-05T19:25:04.997096Z",
     "shell.execute_reply.started": "2021-10-05T19:22:22.725752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.34it/s]\n",
      "334it [02:38,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "support_data = pd.read_csv('../input/snap-retail-data/final_data/support.csv')\n",
    "support_data.drop_duplicates('class', inplace=True)\n",
    "test_query_data = pd.read_csv('../input/snap-retail-data/final_data/test_query.csv')\n",
    "test_query_data.drop(test_query_data[test_query_data['image_id'] == '.DS_Store'].index, inplace=True)\n",
    "\n",
    "data = pd.concat([support_data, valid_query_data, test_query_data], ignore_index=True)\n",
    "class_codes = {}\n",
    "for idx,cl in enumerate(data['class'].unique()):\n",
    "    class_codes[str(cl)] = idx\n",
    "    \n",
    "for idx in data['class'].index:\n",
    "    data.loc[idx,'class_code'] = class_codes[str(data.loc[idx,'class'])]\n",
    "    \n",
    "data['class_code'] = data['class_code'].astype(int)\n",
    "\n",
    "BS = 194\n",
    "BS_test = 1\n",
    "support_df = data[data['type'] == 'support'].reset_index()\n",
    "test_query_df = data[data['type'] == 'test'].reset_index()\n",
    "final_test_data_20_5 = pd.DataFrame()\n",
    "for cl_,val in zip(test_query_df['class'].value_counts().index,test_query_df['class'].value_counts().values):\n",
    "    if val < 20 and val>=5:\n",
    "        df = test_query_df[test_query_df['class'] == cl_]\n",
    "        final_test_data_20_5 = pd.concat([final_test_data_20_5, df], ignore_index = True)\n",
    "dataset = CustomDataset_Support(support_df)\n",
    "support_data_loader = torch.utils.data.DataLoader(dataset, batch_size=194)\n",
    "valid_query_dataset = CustomDataset_Query(valid_query_df)\n",
    "valid_query_data_loader = torch.utils.data.DataLoader(valid_query_dataset, batch_size=BS)\n",
    "test_query_dataset = CustomDataset_Query(final_test_data_20_5, is_trained_class = False)\n",
    "test_query_data_loader = torch.utils.data.DataLoader(test_query_dataset, batch_size=BS_test)\n",
    "\n",
    "model_path = '../input/2-shot-learning/best_model_ResNet-12-sgd-lr_1e-01-gamma_1e-01-epoch_100-stage_2-decay_5e-04-way_10.pth'\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "model = FRN()\n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(model_path,map_location=get_device_map(gpu)),strict=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    c = 0\n",
    "#     for data_load, batch, df in zip([valid_query_data_loader, test_query_data_loader],[BS,BS_test],[valid_query_df, test_query_df]):\n",
    "    for data_load, batch, df in zip([test_query_data_loader],[BS_test],[test_query_df]):\n",
    "        for i, (inp,_) in tqdm(enumerate(support_data_loader)):\n",
    "            inp = inp.cuda()\n",
    "            support_inp = inp\n",
    "        true_label = []\n",
    "        pred_label = []\n",
    "        max_value = []\n",
    "        for i, (inp,target) in tqdm(enumerate(data_load)):\n",
    "            inp = inp.cuda()\n",
    "            target = target.cuda()\n",
    "            max_values, max_index, neg_l2_dist = model.meta_test(support_inp, inp, batch)\n",
    "            true_label.extend(list(target.cpu().numpy()))\n",
    "            pred_label.extend(list(max_index.cpu().numpy()))\n",
    "            max_value.extend(list(max_values.cpu().numpy()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:55:23.457222Z",
     "iopub.status.busy": "2021-10-05T19:55:23.456952Z",
     "iopub.status.idle": "2021-10-05T19:55:23.474332Z",
     "shell.execute_reply": "2021-10-05T19:55:23.473504Z",
     "shell.execute_reply.started": "2021-10-05T19:55:23.457191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Pred Score'] = max_value\n",
    "df['True_Label'] = np.array(true_label) \n",
    "df['Predicted_Label'] = np.array(pred_label)\n",
    "final_test_data_20_5 = pd.concat([final_test_data_20_5, df], axis=1)\n",
    "final_test_data_20_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:57:09.046160Z",
     "iopub.status.busy": "2021-10-05T19:57:09.045886Z",
     "iopub.status.idle": "2021-10-05T19:57:09.052069Z",
     "shell.execute_reply": "2021-10-05T19:57:09.051178Z",
     "shell.execute_reply.started": "2021-10-05T19:57:09.046125Z"
    }
   },
   "outputs": [],
   "source": [
    "final_test_data_20_5['accuracy'] = 1*(final_test_data_20_5['Predicted_Label'] == final_test_data_20_5['True_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:57:13.496018Z",
     "iopub.status.busy": "2021-10-05T19:57:13.495462Z",
     "iopub.status.idle": "2021-10-05T19:57:13.508577Z",
     "shell.execute_reply": "2021-10-05T19:57:13.507783Z",
     "shell.execute_reply.started": "2021-10-05T19:57:13.495981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>class_code</th>\n",
       "      <th>Pred Score</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1162</td>\n",
       "      <td>walmart-neighborhood-market-5657_16514983_Q02-...</td>\n",
       "      <td>999999981529</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.301439</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2126</td>\n",
       "      <td>walmart-neighborhood-market-5855_16497595_Q02-...</td>\n",
       "      <td>999999981529</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.536676</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2514</td>\n",
       "      <td>walmart-neighborhood-market-5613_16495482_Q02-...</td>\n",
       "      <td>999999981529</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.345235</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2598</td>\n",
       "      <td>walmart-neighborhood-market-5657_16514983_Q02-...</td>\n",
       "      <td>999999981529</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.378837</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2897</td>\n",
       "      <td>walmart-supercenter-1521_16510774_Q02-002_zIK9...</td>\n",
       "      <td>999999981529</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.521002</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           image_id         class  \\\n",
       "0   1162  walmart-neighborhood-market-5657_16514983_Q02-...  999999981529   \n",
       "1   2126  walmart-neighborhood-market-5855_16497595_Q02-...  999999981529   \n",
       "2   2514  walmart-neighborhood-market-5613_16495482_Q02-...  999999981529   \n",
       "3   2598  walmart-neighborhood-market-5657_16514983_Q02-...  999999981529   \n",
       "4   2897  walmart-supercenter-1521_16510774_Q02-002_zIK9...  999999981529   \n",
       "\n",
       "   type  class_code  Pred Score  True_Label  Predicted_Label  accuracy  \n",
       "0  test           7   -0.301439           7                7         1  \n",
       "1  test           7   -0.536676           7                7         1  \n",
       "2  test           7   -0.345235           7                7         1  \n",
       "3  test           7   -0.378837           7                7         1  \n",
       "4  test           7   -0.521002           7                7         1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data_20_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:57:57.893759Z",
     "iopub.status.busy": "2021-10-05T19:57:57.893215Z",
     "iopub.status.idle": "2021-10-05T19:57:58.131952Z",
     "shell.execute_reply": "2021-10-05T19:57:58.131165Z",
     "shell.execute_reply.started": "2021-10-05T19:57:57.893723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811377245508982"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu =  []\n",
    "for cl_ in final_test_data_20_5['class']:\n",
    "    d = final_test_data_20_5[final_test_data_20_5['class'] == cl_]\n",
    "    accu.append(d['accuracy'].sum()/len(d))\n",
    "accu = np.mean(accu)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:58:05.564124Z",
     "iopub.status.busy": "2021-10-05T19:58:05.563322Z",
     "iopub.status.idle": "2021-10-05T19:58:05.584709Z",
     "shell.execute_reply": "2021-10-05T19:58:05.584029Z",
     "shell.execute_reply.started": "2021-10-05T19:58:05.564073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>class_code</th>\n",
       "      <th>Pred Score</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>388</td>\n",
       "      <td>walmart-supercenter-1238_16505805_Q02-004_pLiM...</td>\n",
       "      <td>999999981516</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.317165</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513</td>\n",
       "      <td>walmart-supercenter-1080_16507175_Q02-005_7MpQ...</td>\n",
       "      <td>999999981516</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.323810</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>551</td>\n",
       "      <td>walmart-supercenter-1117_16514977_Q02-001_JD5x...</td>\n",
       "      <td>999999981516</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.364363</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>656</td>\n",
       "      <td>walmart-supercenter-147_16507331_Q02-003_2Zzer...</td>\n",
       "      <td>999999981516</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.398736</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>673</td>\n",
       "      <td>walmart-supercenter-1433_16500483_Q02-005_ZULm...</td>\n",
       "      <td>999999981516</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.282852</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           image_id         class  \\\n",
       "0    388  walmart-supercenter-1238_16505805_Q02-004_pLiM...  999999981516   \n",
       "1    513  walmart-supercenter-1080_16507175_Q02-005_7MpQ...  999999981516   \n",
       "2    551  walmart-supercenter-1117_16514977_Q02-001_JD5x...  999999981516   \n",
       "3    656  walmart-supercenter-147_16507331_Q02-003_2Zzer...  999999981516   \n",
       "4    673  walmart-supercenter-1433_16500483_Q02-005_ZULm...  999999981516   \n",
       "\n",
       "   type  class_code  Pred Score  True_Label  Predicted_Label  accuracy  \n",
       "0  test         155   -0.317165         155              155       NaN  \n",
       "1  test         155   -0.323810         155              155       NaN  \n",
       "2  test         155   -0.364363         155               28       NaN  \n",
       "3  test         155   -0.398736         155              155       NaN  \n",
       "4  test         155   -0.282852         155               28       NaN  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_df = pd.concat([final_test_data_20, final_test_data_20_5])\n",
    "final_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T19:59:35.445129Z",
     "iopub.status.busy": "2021-10-05T19:59:35.444825Z",
     "iopub.status.idle": "2021-10-05T19:59:35.456434Z",
     "shell.execute_reply": "2021-10-05T19:59:35.455672Z",
     "shell.execute_reply.started": "2021-10-05T19:59:35.445096Z"
    }
   },
   "outputs": [],
   "source": [
    "final_data_df['accuracy'] =  1*(final_data_df['Predicted_Label'] == final_data_df['True_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T20:00:01.723677Z",
     "iopub.status.busy": "2021-10-05T20:00:01.723085Z",
     "iopub.status.idle": "2021-10-05T20:00:03.960161Z",
     "shell.execute_reply": "2021-10-05T20:00:03.959445Z",
     "shell.execute_reply.started": "2021-10-05T20:00:01.723637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696027633851468"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accu =  []\n",
    "for cl_ in final_data_df['class']:\n",
    "    d = final_data_df[final_data_df['class'] == cl_]\n",
    "    overall_accu.append((d['accuracy'].sum()/len(d)))\n",
    "# overall_accu = overall_accu/final_data_df['class'].nunique()\n",
    "overall_accu = np.mean(overall_accu)\n",
    "overall_accu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
